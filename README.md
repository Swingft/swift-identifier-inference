# Swift Identifier Extractor - RunPod GPU

RunPod GPU í™˜ê²½ì—ì„œ í•™ìŠµëœ LoRA ëª¨ë¸ë¡œ Swift ì‹ë³„ìë¥¼ ì¶”ì¶œí•˜ëŠ” í”„ë¡œì íŠ¸

## âœ¨ ì£¼ìš” íŠ¹ì§•

- âœ… **í•™ìŠµ í˜•ì‹ ì¼ì¹˜**: Alpaca í˜•ì‹ (### Instruction / ### Input / ### Response)
- âœ… **í•´ì‹œ ê¸°ë°˜ ì²´í¬í¬ì¸íŠ¸**: ë™ì¼í•œ ì…ë ¥ì€ ìë™ìœ¼ë¡œ ìŠ¤í‚µ
- ğŸ”„ **ì•ˆì „í•œ ì¤‘ë‹¨/ì¬ê°œ**: Ctrl+Cë¡œ ì¤‘ë‹¨í•´ë„ ì§„í–‰ìƒí™© ë³´ì¡´
- ğŸš€ **GPU ê°€ì†**: CUDA ì§€ì›ìœ¼ë¡œ ë¹ ë¥¸ ì¶”ë¡ 
- ğŸ“Š **í† í° ìˆ˜ í•„í„°ë§**: í•™ìŠµ ì‹œ ì‚¬ìš©í•œ í† í° ì œí•œ ì¤€ìˆ˜

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
swift-identifier-extractor/
â”œâ”€â”€ setup.sh                  # í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ run_inference.py          # ë©”ì¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt          # Python íŒ¨í‚¤ì§€
â”œâ”€â”€ README.md                 # ì´ íŒŒì¼
â”œâ”€â”€ models/                   # ëª¨ë¸ íŒŒì¼ (ì—…ë¡œë“œ í•„ìš”)
â”‚   â”œâ”€â”€ base_model.gguf       # Phi-3-mini-128k-instruct (GGUF)
â”‚   â””â”€â”€ lora.gguf             # í•™ìŠµëœ LoRA ì–´ëŒ‘í„° (GGUF)
â”œâ”€â”€ dataset.jsonl             # ì…ë ¥ ë°ì´í„°ì…‹ (ì—…ë¡œë“œ í•„ìš”)
â”œâ”€â”€ checkpoint/               # ì§„í–‰ìƒí™© ì €ì¥
â”‚   â””â”€â”€ processed.jsonl       # ì²˜ë¦¬ ì™„ë£Œ í•­ëª© (í•´ì‹œ + ê²°ê³¼)
â””â”€â”€ output/                   # ê²°ê³¼ ì¶œë ¥
    â”œâ”€â”€ identifiers.txt       # ì¶”ì¶œëœ ì‹ë³„ì ëª©ë¡
    â””â”€â”€ identifiers_summary.json
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: í™˜ê²½ ì„¤ì •

```bash
# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬ ë° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x setup.sh
bash setup.sh
```

### 2ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ

1. **ëª¨ë¸ íŒŒì¼** â†’ `models/` ë””ë ‰í† ë¦¬
   - `base_model.gguf` (Phi-3-mini-128k-instruct GGUF ë²„ì „)
   - `lora.gguf` (í•™ìŠµëœ LoRA ì–´ëŒ‘í„° GGUF ë²„ì „)

2. **ë°ì´í„°ì…‹** â†’ í”„ë¡œì íŠ¸ ë£¨íŠ¸
   - `dataset.jsonl` (instruction, input í¬í•¨)

### 3ë‹¨ê³„: ì¶”ë¡  ì‹¤í–‰

```bash
python run_inference.py
```

---

## ğŸ“Š ì…ë ¥ ë°ì´í„° í˜•ì‹ (ì¤‘ìš”!)

### JSONL í˜•ì‹ (Alpaca)
```jsonl
{"instruction": "You are an expert Swift code auditor...", "input": "### Swift Source Code:\n```swift\n...\n```\n\n### AST Symbol Information:\n...", "output": "{\"identifiers\": [\"id1\", \"id2\"]}"}
```

**í•„ìˆ˜ í•„ë“œ:**
- `instruction`: ëª¨ë¸ì—ê²Œ ì£¼ëŠ” ì§€ì‹œì‚¬í•­ (í•™ìŠµ ì‹œ ì‚¬ìš©í•œ instructionê³¼ ë™ì¼)
- `input`: Swift ì½”ë“œ + AST + Rule ì •ë³´
- `output`: (ì„ íƒ) ì •ë‹µ ë ˆì´ë¸” (ì¶”ë¡  ì‹œì—ëŠ” ë¬´ì‹œë¨)

**í”„ë¡¬í”„íŠ¸ í˜•ì‹ (ìë™ ìƒì„±):**
```
### Instruction:
{instruction}

### Input:
{input}

### Response:
```

ì´ í˜•ì‹ì€ í•™ìŠµ ì‹œ ì‚¬ìš©í•œ `format_example` í•¨ìˆ˜ì™€ ë™ì¼í•©ë‹ˆë‹¤.

---

## ğŸ›ï¸ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‹¤í–‰
```bash
python run_inference.py
```

### ì»¤ìŠ¤í…€ ì˜µì…˜
```bash
python run_inference.py \
  --dataset my_dataset.jsonl \
  --base_model models/phi-3-mini-128k-instruct.gguf \
  --lora models/phi3_lora_adapter-Q4_K_M.gguf \
  --output output/my_identifiers.txt \
  --ctx 12288 \
  --max_input_tokens 10500 \
  --gpu_layers -1
```

### ì˜µì…˜ ì„¤ëª…

| ì˜µì…˜ | ì„¤ëª… | ê¸°ë³¸ê°’ | ë¹„ê³  |
|------|------|--------|------|
| `--dataset` | ì…ë ¥ JSONL íŒŒì¼ | `dataset.jsonl` | Alpaca í˜•ì‹ |
| `--base_model` | ë² ì´ìŠ¤ ëª¨ë¸ ê²½ë¡œ | `models/base_model.gguf` | Phi-3 GGUF |
| `--lora` | LoRA ì–´ëŒ‘í„° ê²½ë¡œ | `models/lora.gguf` | í•™ìŠµëœ ì–´ëŒ‘í„° |
| `--output` | ì¶œë ¥ íŒŒì¼ ê²½ë¡œ | `output/identifiers.txt` | |
| `--ctx` | ì»¨í…ìŠ¤íŠ¸ í¬ê¸° | `12288` | í•™ìŠµ ì‹œ ì‚¬ìš© |
| `--max_input_tokens` | ìµœëŒ€ ì…ë ¥ í† í° | `10500` | í•„í„°ë§ ê¸°ì¤€ |
| `--gpu_layers` | GPU ë ˆì´ì–´ ìˆ˜ | `-1` (ì „ì²´) | |
| `--reset` | ì²´í¬í¬ì¸íŠ¸ ì´ˆê¸°í™” | `False` | |

---

## ğŸ” í•´ì‹œ ê¸°ë°˜ ì²´í¬í¬ì¸íŠ¸

### ì‘ë™ ì›ë¦¬

1. **í•´ì‹œ ìƒì„±**: `instruction + input`ì„ SHA-256 í•´ì‹±
2. **ìë™ ìŠ¤í‚µ**: ë™ì¼í•œ í•´ì‹œëŠ” ì¬ì²˜ë¦¬í•˜ì§€ ì•ŠìŒ
3. **ê²°ê³¼ ìºì‹±**: ì²´í¬í¬ì¸íŠ¸ì— í•´ì‹œ + ê²°ê³¼ ì €ì¥

### ì²´í¬í¬ì¸íŠ¸ íŒŒì¼ í˜•ì‹

```jsonl
{"hash": "a1b2c3...", "result": {"identifiers": ["id1", "id2"]}}
{"hash": "d4e5f6...", "result": {"identifiers": ["id3", "id4"]}}
```

---

## ğŸ’¾ ì¤‘ë‹¨ ë° ì¬ê°œ

### ìë™ ì²´í¬í¬ì¸íŠ¸
- ì²˜ë¦¬ ì™„ë£Œëœ í•­ëª©ì€ `checkpoint/processed.jsonl`ì— ìë™ ì €ì¥
- **Ctrl+Cë¡œ ì¤‘ë‹¨í•´ë„ ì•ˆì „**
- ë‹¤ìŒ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ì´ì–´ì„œ ì²˜ë¦¬

### ì²´í¬í¬ì¸íŠ¸ ì´ˆê¸°í™”
```bash
python run_inference.py --reset
```

---

## ğŸ“ˆ í† í° ìˆ˜ ê´€ë¦¬

### í•™ìŠµ ì‹œ ì„¤ì •
- **max_length**: 12288 tokens
- **ì‹¤ì œ ë°ì´í„°**: ~10500 tokens ì´í•˜ë¡œ í•„í„°ë§ë¨

### ì¶”ë¡  ì‹œ ì„¤ì •
- **n_ctx**: 12288 (ì…ë ¥ ì»¨í…ìŠ¤íŠ¸)
- **max_tokens**: 8192 (ì¶œë ¥ ìƒì„±)
- **ì…ë ¥ í•„í„°ë§**: ~10500 tokens ì´í•˜ë§Œ ì²˜ë¦¬

### í† í° ìˆ˜ í™•ì¸
```python
# ëŒ€ëµì ì¸ í† í° ìˆ˜ = ë¬¸ì ìˆ˜ / 4
approx_tokens = len(instruction + input_text) / 4
```

---

## ğŸ“¤ ì¶œë ¥ í˜•ì‹

### identifiers.txt
```
APIClient
NetworkManager
UserProfile
calculateScore
validateInput
```

### identifiers_summary.json
```json
{
  "total_items": 1234,
  "processed_items": 1234,
  "total_identifiers": 5678,
  "unique_identifiers": 3456,
  "output_file": "output/identifiers.txt"
}
```

---

## ğŸ”§ GPU ì„¤ì •

### NVIDIA GPU í™•ì¸
```bash
nvidia-smi
```

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
```bash
# ëª¨ë“  ë ˆì´ì–´ë¥¼ GPUì— ë¡œë“œ (ê¶Œì¥)
--gpu_layers -1

# ì¼ë¶€ ë ˆì´ì–´ë§Œ GPUì— ë¡œë“œ
--gpu_layers 32
```

---

## âš ï¸ ë¬¸ì œ í•´ê²°

### CUDA ì—ëŸ¬
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# llama-cpp-python ì¬ì„¤ì¹˜ (CUDA ì§€ì›)
pip uninstall llama-cpp-python
pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# GPU ë ˆì´ì–´ ìˆ˜ ì¤„ì´ê¸°
python run_inference.py --gpu_layers 24

# ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì¤„ì´ê¸° (ë¹„ê¶Œì¥)
python run_inference.py --ctx 8192
```

### í† í° ìˆ˜ ì´ˆê³¼
```bash
# ìµœëŒ€ ì…ë ¥ í† í° ì¤„ì´ê¸°
python run_inference.py --max_input_tokens 8000
```

---

## ğŸ“ ì˜ˆì‹œ ì›Œí¬í”Œë¡œìš°

```bash
# 1. í™˜ê²½ ì„¤ì •
bash setup.sh

# 2. íŒŒì¼ ì—…ë¡œë“œ í™•ì¸
ls models/
ls dataset.jsonl

# 3. ë°ì´í„°ì…‹ í™•ì¸ (ì²« ì¤„ ì¶œë ¥)
head -n 1 dataset.jsonl | python -m json.tool

# 4. ì¶”ë¡  ì‹¤í–‰
python run_inference.py

# 5. ê²°ê³¼ í™•ì¸
cat output/identifiers.txt | wc -l
cat output/identifiers_summary.json

# 6. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
# output/identifiers.txtë¥¼ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ
```

---

## ğŸ¯ í•™ìŠµ í˜•ì‹ê³¼ì˜ ì¼ì¹˜

### í•™ìŠµ ì‹œ ì‚¬ìš©í•œ `format_example` í•¨ìˆ˜
```python
def format_example(ex):
    inst = ex.get("instruction")
    inp = ex.get("input")
    out = ex.get("output")
    
    if inp:
        return f"### Instruction:\n{inst}\n\n### Input:\n{inp}\n\n### Response:\n{out}<|endoftext|>"
    else:
        return f"### Instruction:\n{inst}\n\n### Response:\n{out}<|endoftext|>"
```

### ì¶”ë¡  ì‹œ ì‚¬ìš©í•˜ëŠ” `_format_prompt` ë©”ì„œë“œ
```python
def _format_prompt(self, instruction: str, input_text: str) -> str:
    inst = instruction.strip()
    inp = input_text.strip()
    
    if inp:
        return f"### Instruction:\n{inst}\n\n### Input:\n{inp}\n\n### Response:\n"
    else:
        return f"### Instruction:\n{inst}\n\n### Response:\n"
```

âœ… ì™„ì „íˆ ë™ì¼í•œ í˜•ì‹!

---

## ğŸ’¡ ê°œë°œì ë…¸íŠ¸

- **Alpaca í˜•ì‹**: instruction + input â†’ response êµ¬ì¡°
- **Stop tokens**: `<|endoftext|>`, `###` ì‚¬ìš©
- **í•´ì‹œ ì²´í¬í¬ì¸íŠ¸**: instruction + input ê¸°ë°˜
- **í† í° í•„í„°ë§**: í•™ìŠµ ì‹œ ì œí•œ ì¤€ìˆ˜

---

## ğŸ¤ ê¸°ì—¬

ì´ í”„ë¡œì íŠ¸ëŠ” Swingft í”„ë¡œì íŠ¸ì˜ ì¼ë¶€ì…ë‹ˆë‹¤.

---

## ğŸ“„ ë¼ì´ì„¼ìŠ¤

MIT