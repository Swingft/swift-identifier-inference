# Swift Identifier Extractor - RunPod GPU

RunPod GPU í™˜ê²½ì—ì„œ Swift ì†ŒìŠ¤ì½”ë“œ ë°ì´í„°ì…‹ìœ¼ë¡œë¶€í„° ì‹ë³„ìë¥¼ ì¶”ì¶œí•˜ëŠ” í”„ë¡œì íŠ¸

## ğŸ“ í”„ë¡œì íŠ¸ êµ¬ì¡°

```
swift-identifier-extractor/
â”œâ”€â”€ setup.sh                  # í™˜ê²½ ì„¤ì • ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ run_inference.py          # ë©”ì¸ ì¶”ë¡  ìŠ¤í¬ë¦½íŠ¸
â”œâ”€â”€ requirements.txt          # Python íŒ¨í‚¤ì§€
â”œâ”€â”€ README.md                 # ì´ íŒŒì¼
â”œâ”€â”€ models/                   # ëª¨ë¸ íŒŒì¼ (ì—…ë¡œë“œ í•„ìš”)
â”‚   â”œâ”€â”€ base_model.gguf       # ë² ì´ìŠ¤ ëª¨ë¸
â”‚   â””â”€â”€ lora.gguf             # LoRA ì–´ëŒ‘í„°
â”œâ”€â”€ dataset.jsonl             # ì…ë ¥ ë°ì´í„°ì…‹ (ì—…ë¡œë“œ í•„ìš”)
â”œâ”€â”€ checkpoint/               # ì§„í–‰ìƒí™© ì €ì¥
â”‚   â””â”€â”€ processed.txt         # ì²˜ë¦¬ ì™„ë£Œ íŒŒì¼ ëª©ë¡
â””â”€â”€ output/                   # ê²°ê³¼ ì¶œë ¥
    â”œâ”€â”€ identifiers.txt       # ì¶”ì¶œëœ ì‹ë³„ì ëª©ë¡
    â””â”€â”€ identifiers_summary.json
```

## ğŸš€ ë¹ ë¥¸ ì‹œì‘

### 1ë‹¨ê³„: í™˜ê²½ ì„¤ì •

```bash
# ì‹¤í–‰ ê¶Œí•œ ë¶€ì—¬ ë° ì„¤ì • ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰
chmod +x setup.sh
bash setup.sh
```

### 2ë‹¨ê³„: íŒŒì¼ ì—…ë¡œë“œ

1. **ëª¨ë¸ íŒŒì¼** â†’ `models/` ë””ë ‰í† ë¦¬
   - `base_model.gguf` (ë² ì´ìŠ¤ ëª¨ë¸)
   - `lora.gguf` (LoRA ì–´ëŒ‘í„°)

2. **ë°ì´í„°ì…‹** â†’ í”„ë¡œì íŠ¸ ë£¨íŠ¸
   - `dataset.jsonl`

### 3ë‹¨ê³„: ì¶”ë¡  ì‹¤í–‰

```bash
python run_inference.py
```

---

## ğŸ›ï¸ ì‚¬ìš©ë²•

### ê¸°ë³¸ ì‹¤í–‰
```bash
python run_inference.py
```

### ì»¤ìŠ¤í…€ ì˜µì…˜
```bash
python run_inference.py \
  --dataset my_dataset.jsonl \
  --base_model models/phi-3-128k.gguf \
  --lora models/my_lora.gguf \
  --output output/my_identifiers.txt \
  --ctx 8192 \
  --gpu_layers -1
```

### ì˜µì…˜ ì„¤ëª…

| ì˜µì…˜ | ì„¤ëª… | ê¸°ë³¸ê°’ |
|------|------|--------|
| `--dataset` | ì…ë ¥ JSONL íŒŒì¼ | `dataset.jsonl` |
| `--base_model` | ë² ì´ìŠ¤ ëª¨ë¸ ê²½ë¡œ | `models/base_model.gguf` |
| `--lora` | LoRA ì–´ëŒ‘í„° ê²½ë¡œ | `models/lora.gguf` |
| `--output` | ì¶œë ¥ íŒŒì¼ ê²½ë¡œ | `output/identifiers.txt` |
| `--ctx` | ì»¨í…ìŠ¤íŠ¸ í¬ê¸° | `8192` |
| `--gpu_layers` | GPU ë ˆì´ì–´ ìˆ˜ (-1 = ì „ì²´) | `-1` |
| `--reset` | ì²´í¬í¬ì¸íŠ¸ ì´ˆê¸°í™” | `False` |

---

## ğŸ’¾ ì¤‘ë‹¨ ë° ì¬ê°œ

### ìë™ ì²´í¬í¬ì¸íŠ¸
- ì²˜ë¦¬ ì™„ë£Œëœ íŒŒì¼ì€ `checkpoint/processed.txt`ì— ìë™ ì €ì¥
- **Ctrl+Cë¡œ ì¤‘ë‹¨í•´ë„ ì•ˆì „**
- ë‹¤ìŒ ì‹¤í–‰ ì‹œ ìë™ìœ¼ë¡œ ì´ì–´ì„œ ì²˜ë¦¬

### ì²´í¬í¬ì¸íŠ¸ ì´ˆê¸°í™”
```bash
python run_inference.py --reset
```

---

## ğŸ“Š ì…ë ¥ ë°ì´í„° í˜•ì‹

### JSONL í˜•ì‹
```jsonl
{"filename": "Alamofire_Session.swift", "repo": "Alamofire", "code": "import Foundation\n...", "size": 12345}
{"filename": "Kingfisher_ImageCache.swift", "repo": "Kingfisher", "code": "import UIKit\n...", "size": 8900}
```

**í•„ìˆ˜ í•„ë“œ:**
- `filename`: íŒŒì¼ëª…
- `repo`: ë ˆí¬ì§€í† ë¦¬ ì´ë¦„
- `code`: Swift ì†ŒìŠ¤ì½”ë“œ

---

## ğŸ“¤ ì¶œë ¥ í˜•ì‹

### identifiers.txt
```
APIClient
NetworkManager
UserProfile
calculateScore
validateInput
```

### identifiers_summary.json
```json
{
  "total_items": 1234,
  "processed_items": 1234,
  "total_identifiers": 5678,
  "unique_identifiers": 3456,
  "output_file": "output/identifiers.txt"
}
```

---

## ğŸ”§ GPU ì„¤ì •

### NVIDIA GPU í™•ì¸
```bash
nvidia-smi
```

### GPU ë©”ëª¨ë¦¬ ìµœì í™”
```python
# ëª¨ë“  ë ˆì´ì–´ë¥¼ GPUì— ë¡œë“œ (ê¶Œì¥)
--gpu_layers -1

# ì¼ë¶€ ë ˆì´ì–´ë§Œ GPUì— ë¡œë“œ
--gpu_layers 32
```

---

## ğŸ“ˆ ì„±ëŠ¥ íŒ

1. **ì»¨í…ìŠ¤íŠ¸ í¬ê¸°**: í° íŒŒì¼ì´ ë§ìœ¼ë©´ `--ctx 16384` ì‚¬ìš©
2. **GPU ë ˆì´ì–´**: ë©”ëª¨ë¦¬ê°€ ì¶©ë¶„í•˜ë©´ `-1` (ì „ì²´ ë¡œë“œ)
3. **ë°°ì¹˜ ì²˜ë¦¬**: í˜„ì¬ëŠ” ìˆœì°¨ ì²˜ë¦¬ (ì•ˆì •ì„± ìš°ì„ )

---

## âš ï¸ ë¬¸ì œ í•´ê²°

### CUDA ì—ëŸ¬
```bash
# CUDA ë²„ì „ í™•ì¸
nvidia-smi

# llama-cpp-python ì¬ì„¤ì¹˜ (CUDA ì§€ì›)
pip uninstall llama-cpp-python
pip install llama-cpp-python --extra-index-url https://abetlen.github.io/llama-cpp-python/whl/cu121
```

### ë©”ëª¨ë¦¬ ë¶€ì¡±
```bash
# GPU ë ˆì´ì–´ ìˆ˜ ì¤„ì´ê¸°
python run_inference.py --gpu_layers 24

# ë˜ëŠ” ì»¨í…ìŠ¤íŠ¸ í¬ê¸° ì¤„ì´ê¸°
python run_inference.py --ctx 4096
```

### ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨
- ëª¨ë¸ íŒŒì¼ ê²½ë¡œ í™•ì¸
- íŒŒì¼ ê¶Œí•œ í™•ì¸ (`chmod 644 models/*.gguf`)
- ì¶©ë¶„í•œ ë””ìŠ¤í¬ ê³µê°„ í™•ì¸

---

## ğŸ“ ì˜ˆì‹œ ì›Œí¬í”Œë¡œìš°

```bash
# 1. í™˜ê²½ ì„¤ì •
bash setup.sh

# 2. íŒŒì¼ ì—…ë¡œë“œ í™•ì¸
ls models/
ls dataset.jsonl

# 3. ì¶”ë¡  ì‹¤í–‰
python run_inference.py

# 4. ê²°ê³¼ í™•ì¸
cat output/identifiers.txt | wc -l
cat output/identifiers_summary.json

# 5. ê²°ê³¼ ë‹¤ìš´ë¡œë“œ
# output/identifiers.txt íŒŒì¼ì„ ë¡œì»¬ë¡œ ë‹¤ìš´ë¡œë“œ
```

---

## ğŸ”„ ì¬ì‹¤í–‰ ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì¤‘ë‹¨ í›„ ì¬ê°œ
```bash
# ê·¸ëƒ¥ ë‹¤ì‹œ ì‹¤í–‰í•˜ë©´ ìë™ìœ¼ë¡œ ì´ì–´ì„œ ì²˜ë¦¬ë¨
python run_inference.py
```

### ì‹œë‚˜ë¦¬ì˜¤ 2: ì²˜ìŒë¶€í„° ë‹¤ì‹œ ì‹œì‘
```bash
# ì²´í¬í¬ì¸íŠ¸ ì´ˆê¸°í™”
python run_inference.py --reset
```

### ì‹œë‚˜ë¦¬ì˜¤ 3: ë‹¤ë¥¸ ë°ì´í„°ì…‹ìœ¼ë¡œ ì‹¤í–‰
```bash
# ìƒˆ ë°ì´í„°ì…‹ + ìƒˆ ì¶œë ¥ íŒŒì¼
python run_inference.py \
  --dataset new_dataset.jsonl \
  --output output/new_identifiers.txt
```

---

## ğŸ’¡ ê°œë°œì ë…¸íŠ¸

- **ìˆœì°¨ ì²˜ë¦¬**: ëª¨ë¸ ì•ˆì •ì„±ì„ ìœ„í•´ í˜„ì¬ëŠ” ìˆœì°¨ ì²˜ë¦¬ (ë°°ì¹˜ ì²˜ë¦¬ëŠ” í–¥í›„ ì¶”ê°€ ê°€ëŠ¥)
- **ì²´í¬í¬ì¸íŠ¸**: íŒŒì¼ ë‹¨ìœ„ë¡œ ì €ì¥ë˜ë¯€ë¡œ ì•ˆì „í•˜ê²Œ ì¤‘ë‹¨ ê°€ëŠ¥
- **ì¤‘ë³µ ì œê±°**: ì‹¤ì‹œê°„ìœ¼ë¡œ ì¤‘ë³µì´ ì œê±°ë˜ì–´ ì €ì¥ë¨

---

## ğŸ“ ì§€ì›

ë¬¸ì œê°€ ë°œìƒí•˜ë©´:
1. `output/identifiers_summary.json` í™•ì¸
2. `checkpoint/processed.txt` í™•ì¸
3. ë¡œê·¸ ë©”ì‹œì§€ í™•ì¸