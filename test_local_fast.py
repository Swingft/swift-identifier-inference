#!/usr/bin/env python3
"""
test_local_fast.py

ë§¥ë¶ì—ì„œ ë¹ ë¥´ê²Œ í…ŒìŠ¤íŠ¸í•˜ëŠ” ìµœì í™” ë²„ì „
- ì…ë ¥ ê¸¸ì´ ì œí•œ
- ì‘ì€ ì»¨í…ìŠ¤íŠ¸ í¬ê¸°
- chat_completion ì‚¬ìš©
"""

import json
from llama_cpp import Llama


def truncate_input(text: str, max_chars: int = 8000) -> str:
    """ì…ë ¥ í…ìŠ¤íŠ¸ë¥¼ ì œí•œ"""
    if len(text) <= max_chars:
        return text
    return text[:max_chars] + "\n...(truncated)"


def test_inference():
    """ë¹ ë¥¸ ì¶”ë¡  í…ŒìŠ¤íŠ¸"""

    print("=" * 60)
    print("ë§¥ë¶ ë¹ ë¥¸ í…ŒìŠ¤íŠ¸ (ìµœì í™” ë²„ì „)")
    print("=" * 60)

    # ì„¤ì •
    BASE_MODEL = "models/base_model.gguf"
    LORA_MODEL = "models/lora.gguf"
    DATASET = "dataset.jsonl"

    # ë°ì´í„°ì…‹ ë¡œë“œ (ì²˜ìŒ 3ê°œë§Œ)
    print("\n[1/3] ë°ì´í„°ì…‹ ë¡œë“œ...")
    items = []
    with open(DATASET, 'r', encoding='utf-8') as f:
        for i, line in enumerate(f):
            if i >= 3:
                break
            items.append(json.loads(line))

    print(f"âœ“ {len(items)}ê°œ í•­ëª© ë¡œë“œ")

    # ëª¨ë¸ ë¡œë“œ (ì‘ì€ ì»¨í…ìŠ¤íŠ¸)
    print("\n[2/3] ëª¨ë¸ ë¡œë“œ...")
    print("(Metal GPU + ìµœì í™” ì„¤ì •)")

    model = Llama(
        model_path=BASE_MODEL,
        lora_path=LORA_MODEL,
        n_ctx=4096,  # ì‘ì€ ì»¨í…ìŠ¤íŠ¸ (í…ŒìŠ¤íŠ¸ìš©)
        n_gpu_layers=-1,
        n_threads=4,
        verbose=False
    )

    print("âœ“ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")

    # ì¶”ë¡  ì‹¤í–‰
    print("\n[3/3] ì¶”ë¡  ì‹¤í–‰...")
    print("-" * 60)

    for i, item in enumerate(items, 1):
        instruction = item.get('instruction', '')
        input_text = item.get('input', '')

        # ì…ë ¥ ê¸¸ì´ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
        input_text_short = truncate_input(input_text, max_chars=6000)

        original_len = len(input_text)
        truncated_len = len(input_text_short)

        print(f"\n[{i}/3] í•­ëª© {i}")
        print(f"  ì›ë³¸ input: {original_len} chars (~{original_len // 4} tokens)")
        print(f"  ì¶•ì•½ input: {truncated_len} chars (~{truncated_len // 4} tokens)")

        # chat_completion ì‚¬ìš© (ë” ë¹ ë¦„)
        messages = [
            {
                "role": "system",
                "content": instruction
            },
            {
                "role": "user",
                "content": input_text_short
            }
        ]

        print(f"  ì¶”ë¡  ì¤‘...")
        response = model.create_chat_completion(
            messages=messages,
            max_tokens=1024,  # í…ŒìŠ¤íŠ¸ìš©ìœ¼ë¡œ ì¤„ì„
            temperature=0.1,
            top_p=0.95,
            stop=["<|endoftext|>", "###"]
        )

        output = response['choices'][0]['message']['content'].strip()

        # ì‹ë³„ì ì¶”ì¶œ
        identifiers = extract_identifiers(output)

        if identifiers:
            print(f"  âœ“ {len(identifiers)}ê°œ ì‹ë³„ì ë°œê²¬:")
            for id in identifiers[:10]:
                print(f"    - {id}")
            if len(identifiers) > 10:
                print(f"    ... ì™¸ {len(identifiers) - 10}ê°œ")
        else:
            print(f"  âœ— ì‹ë³„ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            print(f"\n  ì›ë³¸ ì¶œë ¥ (ì²˜ìŒ 200ì):")
            print(f"  {output[:200]}")
            print("  ...")

    print("\n" + "=" * 60)
    print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 60)
    print("\nğŸ’¡ ì‹¤ì œ RunPodì—ì„œëŠ”:")
    print("   - n_ctx=12288 ì‚¬ìš©")
    print("   - ì…ë ¥ ì œí•œ ì—†ìŒ")
    print("   - create_completion ì‚¬ìš© (Alpaca í˜•ì‹)")


def extract_identifiers(output: str) -> list:
    """ëª¨ë¸ ì¶œë ¥ì—ì„œ ì‹ë³„ì ì¶”ì¶œ"""
    import re

    # ë°©ë²• 1: JSON ë¸”ë¡
    try:
        start = output.find('{')
        end = output.rfind('}')
        if start != -1 and end != -1:
            json_str = output[start:end + 1]
            json_str = re.sub(r'/\*.*?\*/', '', json_str, flags=re.DOTALL)
            json_str = re.sub(r'//.*?$', '', json_str, flags=re.MULTILINE)
            data = json.loads(json_str)
            if 'identifiers' in data:
                return data['identifiers']
    except:
        pass

    # ë°©ë²• 2: ë°°ì—´ë§Œ
    try:
        array_match = re.search(r'\[([^\]]+)\]', output)
        if array_match:
            array_str = '[' + array_match.group(1) + ']'
            identifiers = json.loads(array_str)
            return [str(id).strip() for id in identifiers if id]
    except:
        pass

    # ë°©ë²• 3: ë”°ì˜´í‘œ
    try:
        identifiers = re.findall(r'"([^"]+)"', output)
        identifiers = [id for id in identifiers
                       if id not in ['identifiers', 'reasoning']
                       and len(id) > 1]
        if identifiers:
            return identifiers[:20]
    except:
        pass

    return []


if __name__ == '__main__':
    try:
        test_inference()
    except FileNotFoundError as e:
        print(f"\nâŒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
        print("\ní•„ìš”í•œ íŒŒì¼:")
        print("  - models/base_model.gguf")
        print("  - models/lora.gguf")
        print("  - dataset.jsonl")
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì¤‘ë‹¨ë¨")
    except Exception as e:
        print(f"\nâŒ ì—ëŸ¬: {e}")
        import traceback

        traceback.print_exc()