{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Swift Identifier Extractor - RunPod Quick Start\n",
    "\n",
    "이 노트북은 RunPod GPU 환경에서 Swift 식별자를 추출하는 빠른 시작 가이드입니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 환경 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 환경 설정 스크립트 실행\n",
    "!bash setup.sh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CUDA 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NVIDIA GPU 정보\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 파일 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "\n",
    "# 필수 파일 확인\n",
    "required_files = [\n",
    "    'models/base_model.gguf',\n",
    "    'models/lora.gguf',\n",
    "    'dataset.jsonl'\n",
    "]\n",
    "\n",
    "print(\"필수 파일 확인:\")\n",
    "for file in required_files:\n",
    "    exists = \"✅\" if os.path.exists(file) else \"❌\"\n",
    "    print(f\"{exists} {file}\")\n",
    "\n",
    "# 데이터셋 크기 및 구조 확인\n",
    "if os.path.exists('dataset.jsonl'):\n",
    "    with open('dataset.jsonl', 'r') as f:\n",
    "        lines = [line.strip() for line in f if line.strip()]\n",
    "        line_count = len(lines)\n",
    "        \n",
    "    print(f\"\\n데이터셋: {line_count}개 항목\")\n",
    "    \n",
    "    # 첫 번째 항목 구조 확인\n",
    "    if lines:\n",
    "        first_item = json.loads(lines[0])\n",
    "        print(\"\\n데이터셋 구조:\")\n",
    "        for key in first_item.keys():\n",
    "            print(f\"  - {key}\")\n",
    "        \n",
    "        # file_path 예시\n",
    "        if 'file_path' in first_item:\n",
    "            print(f\"\\n예시 file_path: {first_item['file_path']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 추론 실행 (기본 설정)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 기본 설정으로 실행\n",
    "!python run_inference.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 커스텀 설정으로 실행 (선택사항)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 커스텀 설정 예시\n",
    "!python run_inference.py \\\n",
    "    --dataset dataset.jsonl \\\n",
    "    --base_model models/base_model.gguf \\\n",
    "    --lora models/lora.gguf \\\n",
    "    --output output/identifiers.txt \\\n",
    "    --ctx 8192 \\\n",
    "    --gpu_layers -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 결과 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# 요약 정보 출력\n",
    "with open('output/identifiers_summary.json', 'r') as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "print(\"=\" * 50)\n",
    "print(\"결과 요약\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"처리된 항목: {summary['processed_items']}개\")\n",
    "print(f\"총 식별자: {summary['total_identifiers']}개\")\n",
    "print(f\"고유 식별자: {summary['unique_identifiers']}개\")\n",
    "print(f\"출력 파일: {summary['output_file']}\")\n",
    "\n",
    "# 식별자 샘플 출력\n",
    "print(\"\\n식별자 샘플 (상위 20개):\")\n",
    "print(\"-\" * 50)\n",
    "with open('output/identifiers.txt', 'r') as f:\n",
    "    for i, line in enumerate(f):\n",
    "        if i >= 20:\n",
    "            break\n",
    "        print(line.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 체크포인트 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# 처리 완료된 파일 확인\n",
    "if os.path.exists('checkpoint/processed.txt'):\n",
    "    with open('checkpoint/processed.txt', 'r') as f:\n",
    "        processed = [line.strip() for line in f if line.strip()]\n",
    "    print(f\"처리 완료: {len(processed)}개 파일\")\n",
    "    \n",
    "    # 처음 5개 경로 출력\n",
    "    if processed:\n",
    "        print(\"\\n예시 (처음 5개):\")\n",
    "        for path in processed[:5]:\n",
    "            print(f\"  ✓ {path}\")\n",
    "else:\n",
    "    print(\"아직 처리된 파일이 없습니다.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 체크포인트 초기화 (처음부터 다시 시작)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 체크포인트 초기화\n",
    "!python run_inference.py --reset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 결과 다운로드 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 파일 압축\n",
    "!zip -r results.zip output/ checkpoint/\n",
    "print(\"\\n✅ results.zip 생성 완료!\")\n",
    "print(\"파일 탐색기에서 다운로드하세요.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 데이터셋 통계 (추가 분석)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from collections import Counter\n",
    "import os\n",
    "\n",
    "# 데이터셋 분석\n",
    "print(\"데이터셋 상세 통계\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# 레포지토리별 파일 수 집계\n",
    "repo_counts = Counter()\n",
    "total_size = 0\n",
    "\n",
    "with open('dataset.jsonl', 'r') as f:\n",
    "    for line in f:\n",
    "        if line.strip():\n",
    "            item = json.loads(line)\n",
    "            file_path = item['file_path']\n",
    "            \n",
    "            # 레포지토리 이름 추출 (첫 번째 디렉토리)\n",
    "            repo = file_path.split('/')[0]\n",
    "            repo_counts[repo] += 1\n",
    "            \n",
    "            # 코드 길이\n",
    "            total_size += len(item['content'])\n",
    "\n",
    "print(f\"총 파일 수: {sum(repo_counts.values())}개\")\n",
    "print(f\"총 코드 크기: {total_size:,} bytes\")\n",
    "print(f\"레포지토리 수: {len(repo_counts)}개\")\n",
    "print(\"\\n레포지토리별 파일 수 (상위 10개):\")\n",
    "\n",
    "for repo, count in repo_counts.most_common(10):\n",
    "    print(f\"  {repo}: {count}개\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
